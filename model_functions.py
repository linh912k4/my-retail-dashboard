# -*- coding: utf-8 -*-
"""model_functions

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1znlQT0YyP_4izxgHGPLo_RqaXdji-G-x
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score
from sklearn.linear_model import LinearRegression
from prophet import Prophet # Make sure you have prophet installed
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV
from lightgbm import LGBMRegressor # Make sure you have lightgbm installed
import io

# --- Preprocessing Function (Centralized) ---
def preprocess_data_for_models(
    transaction_path="transaction_data_2023_2024_updated.csv",
    promotion_path="promotion_data.csv.csv",
    store_path="store_info_data_2023_2024_updated.csv.csv"
):
    """
    Loads and preprocesses data for all forecasting models.
    Returns the final merged and cleaned DataFrame (df_final).
    """
    df_transaction = pd.read_csv(transaction_path)
    df_promotion = pd.read_csv(promotion_path)
    df_store = pd.read_csv(store_path)

    # Drop duplicates
    df_transaction.drop_duplicates(inplace=True)
    df_promotion.drop_duplicates(inplace=True)
    df_store.drop_duplicates(inplace=True)

    # Convert dates
    df_transaction['Date'] = pd.to_datetime(df_transaction['Date'])
    df_promotion['Start_Date'] = pd.to_datetime(df_promotion['Start_Date'])
    df_promotion['End_Date'] = pd.to_datetime(df_promotion['End_Date'])

    # Extract time features
    df_transaction['Year'] = df_transaction['Date'].dt.year
    df_transaction['Month'] = df_transaction['Date'].dt.month
    df_transaction['Quarter'] = df_transaction['Date'].dt.quarter

    # Normalize and encode Promo_Type
    df_promotion['Promo_Type'] = df_promotion['Promo_Type'].str.lower().str.strip()
    promo_type_mapping = {'no promotion': 0, 'discount': 1, 'trade-in': 2}
    df_promotion['Promo_Type_Code'] = df_promotion['Promo_Type'].map(promo_type_mapping)

    # Initialize promotion columns in transaction
    df_transaction['Promo_ID'] = 'No Promo' # Initialize with 'No Promo'
    df_transaction['Promo_Type_Code'] = 0
    df_transaction['Promo_Budget'] = 0

    # Assign promotion info based on date range
    for _, promo_row in df_promotion.iterrows():
        mask = (df_transaction['Date'] >= promo_row['Start_Date']) & \
               (df_transaction['Date'] <= promo_row['End_Date'])
        df_transaction.loc[mask, 'Promo_ID'] = promo_row['Promo_ID']
        df_transaction.loc[mask, 'Promo_Type_Code'] = promo_row['Promo_Type_Code']
        df_transaction.loc[mask, 'Promo_Budget'] = promo_row['Budget'] # Corrected column name

    # Merge store info
    df_store_clean = df_store[['Store_ID', 'Store_Size']].drop_duplicates()
    df_final = df_transaction.merge(df_store_clean, on='Store_ID', how='left')

    # Handle missing values for Promo_ID and Store_Size
    df_final['Promo_ID'] = df_final['Promo_ID'].fillna('No Promo')
    df_final['Store_Size'] = df_final['Store_Size'].fillna(df_final['Store_Size'].median())

    # Clean negative values
    cols_to_clean = ['Quantity_Sold', 'Price', 'Stock_Level', 'Reorder_Threshold', 'Revenue']
    for col in cols_to_clean:
        df_final[col] = df_final[col].apply(lambda x: x if x >= 0 else np.nan)

    # Drop rows with critical missing values
    df_final.dropna(subset=['Quantity_Sold', 'Price', 'Stock_Level'], inplace=True)
    df_final.reset_index(drop=True, inplace=True)

    return df_final

# --- Linear Regression Model ---
def run_linear_regression(df_final, st):
    st.subheader("Mô hình Dự báo: Hồi quy Tuyến tính (Linear Regression)")
    st.write("---")

    df = df_final.copy()
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.sort_values('Date').set_index('Date')

    daily = df.resample('D').agg({
        'Quantity_Sold':'sum',
        'Price':'mean',
        'Stock_Level':'sum',
        'Reorder_Threshold':'mean',
        'Promo_Budget':'sum', # Use Promo_Budget instead of Budget
        'Store_Size':'mean',
        'Promo_Type_Code':'mean'
    }).rename(columns={
        'Price':'Avg_Price',
        'Stock_Level':'Total_Stock',
        'Reorder_Threshold':'Avg_Reorder_Threshold',
        'Promo_Budget':'Total_Budget', # Renamed
        'Store_Size':'Avg_Store_Size',
        'Promo_Type_Code':'Avg_Promo_Code'
    })

    daily.fillna({
        'Quantity_Sold': 0,
        'Total_Stock': 0,
        'Total_Budget': 0
    }, inplace=True)
    for col in ['Avg_Price','Avg_Reorder_Threshold','Avg_Store_Size','Avg_Promo_Code']:
        daily[col].fillna(method='ffill', inplace=True)
        daily[col].fillna(0, inplace=True)

    daily['t'] = np.arange(len(daily))
    for p in [7,14,30,90,365]:
        daily[f'sin{p}'] = np.sin(2*np.pi*daily['t']/p)
        daily[f'cos{p}'] = np.cos(2*np.pi*daily['t']/p)

    for lag in [1,2,3,7,14,30]:
        daily[f'lag_{lag}'] = daily['Quantity_Sold'].shift(lag).fillna(0)

    for w in [3,7,14,30]:
        daily[f'roll_{w}'] = daily['Quantity_Sold'].shift(1).rolling(w).mean().fillna(0)

    daily['dow'] = daily.index.dayofweek
    daily['month'] = daily.index.month
    daily = pd.concat([
        daily,
        pd.get_dummies(daily['dow'], prefix='dow'),
        pd.get_dummies(daily['month'], prefix='mon')
    ], axis=1)

    features = ['t'] + \
               [f'sin{p}' for p in [7,14,30,90,365]] + \
               [f'cos{p}' for p in [7,14,30,90,365]] + \
               ['Avg_Price','Total_Stock','Avg_Reorder_Threshold','Total_Budget','Avg_Store_Size','Avg_Promo_Code'] + \
               [f'lag_{l}' for l in [1,2,3,7,14,30]] + \
               [f'roll_{w}' for w in [3,7,14,30]] + \
               [c for c in daily.columns if c.startswith('dow_') or c.startswith('mon_')]

    # Filter features to only include those present in daily.columns
    features = [f for f in features if f in daily.columns]

    daily.dropna(subset=features+['Quantity_Sold'], inplace=True)

    X = daily[features].values
    y = daily['Quantity_Sold'].values
    split = int(len(X)*0.8)
    X_train, X_test = X[:split], X[split:]
    y_train, y_test = y[:split], y[split:]

    scaler = StandardScaler()
    X_train_s = scaler.fit_transform(X_train)
    X_test_s = scaler.transform(X_test)

    model = LinearRegression()
    model.fit(X_train_s, y_train)

    y_pred = model.predict(X_test_s)

    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mape = mean_absolute_percentage_error(y_test, y_pred)*100
    r2 = r2_score(y_test, y_pred)

    st.write("#### Kết quả đánh giá mô hình:")
    st.write(f"**MAE:** {mae:.2f}")
    st.write(f"**RMSE:** {rmse:.2f}")
    st.write(f"**MAPE:** {mape:.2f}%")
    st.write(f"**R²:** {r2:.3f}")

    fig_lr = plt.figure(figsize=(12,5))
    plt.plot(daily.index, daily['Quantity_Sold'], label='Actual')
    plt.plot(daily.index[split:], y_pred, '--', label='Linear Forecast')
    plt.title('Linear Regression Forecast vs Actual Sales')
    plt.xlabel('Date')
    plt.ylabel('Quantity Sold')
    plt.legend()
    plt.tight_layout()
    st.pyplot(fig_lr)
    st.write("---")


# --- Prophet Model ---
def run_prophet_model(df_final, st):
    st.subheader("Mô hình Dự báo: Prophet")
    st.write("---")

    df = df_final.copy()
    df['Date'] = pd.to_datetime(df['Date'])
    df_daily = df.groupby('Date')['Quantity_Sold'].sum().reset_index()
    df_daily = df_daily.rename(columns={'Date': 'ds', 'Quantity_Sold': 'y'})

    model = Prophet(daily_seasonality=True)
    model.fit(df_daily)

    future = model.make_future_dataframe(periods=365)
    forecast = model.predict(future)

    merged = df_daily.merge(forecast[['ds', 'yhat']], on='ds', how='left')
    y_true = merged['y'].dropna() # Drop NA for comparison
    y_pred = merged['yhat'][merged['y'].notna()] # Align predictions with actuals

    if not y_true.empty:
        mae = mean_absolute_error(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
        r2 = r2_score(y_true, y_pred)

        st.write("#### Kết quả đánh giá mô hình (trên dữ liệu lịch sử):")
        st.write(f"**MAE:** {mae:.2f}")
        st.write(f"**RMSE:** {rmse:.2f}")
        st.write(f"**MAPE:** {mape:.2f}%")
        st.write(f"**R²:** {r2:.2f}")
    else:
        st.write("Không đủ dữ liệu lịch sử để đánh giá mô hình Prophet.")


    fig_prophet = plt.figure(figsize=(14, 6))
    plt.plot(forecast['ds'], forecast['yhat'], label='Forecast')
    plt.plot(df_daily['ds'], df_daily['y'], label='Actual')
    plt.title("Prophet Forecast for Next 12 Months (Daily)")
    plt.xlabel("Date")
    plt.ylabel("Sales")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    st.pyplot(fig_prophet)
    st.write("---")

# --- LSTM Model ---
def run_lstm_model(df_final, st):
    st.subheader("Mô hình Dự báo: LSTM")
    st.write("---")

    df = df_final.copy()
    df['Date'] = pd.to_datetime(df['Date']) # Corrected column name to 'Date'
    df = df.sort_values('Date').reset_index(drop=True)

    df_daily = df.groupby('Date')['Quantity_Sold'].sum().reset_index()
    df_daily = df_daily.set_index('Date').sort_index()

    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(df_daily[['Quantity_Sold']])

    def create_sequences(data, seq_length=30):
        X, y = [], []
        for i in range(len(data) - seq_length):
            X.append(data[i:i+seq_length])
            y.append(data[i+seq_length])
        return np.array(X), np.array(y)

    SEQ_LEN = 30
    # Ensure there's enough data for sequence creation
    if len(scaled_data) <= SEQ_LEN:
        st.warning(f"Không đủ dữ liệu ({len(scaled_data)} điểm) để tạo chuỗi LSTM với độ dài {SEQ_LEN}. Bỏ qua mô hình LSTM.")
        return

    X, y = create_sequences(scaled_data, SEQ_LEN)

    split = int(0.8 * len(X))
    X_train, X_test = X[:split], X[split:]
    y_train, y_test = y[:split], y[split:]

    model = Sequential()
    model.add(LSTM(64, return_sequences=True, input_shape=(SEQ_LEN, 1)))
    model.add(Dropout(0.2))
    model.add(LSTM(32))
    model.add(Dropout(0.2))
    model.add(Dense(1))

    model.compile(optimizer='adam', loss='mean_squared_error')

    # Use st.spinner to show loading
    with st.spinner('Đang huấn luyện mô hình LSTM...'):
        history = model.fit(
            X_train, y_train,
            epochs=10, # Reduced epochs for faster execution in Streamlit demo
            batch_size=32,
            validation_split=0.1,
            verbose=0 # Suppress verbose output
        )
    st.success("Huấn luyện mô hình LSTM hoàn tất.")

    y_pred_scaled = model.predict(X_test)
    y_pred = scaler.inverse_transform(y_pred_scaled)
    y_test_inv = scaler.inverse_transform(y_test)

    mae = mean_absolute_error(y_test_inv, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred))
    mape = np.mean(np.abs((y_test_inv - y_pred) / y_test_inv)) * 100
    r2 = r2_score(y_test_inv, y_pred)

    st.write("#### Kết quả đánh giá mô hình:")
    st.write(f"**MAE:** {mae:.2f}")
    st.write(f"**RMSE:** {rmse:.2f}")
    st.write(f"**MAPE:** {mape:.2f}%")
    st.write(f"**R²:** {r2:.2f}")

    fig_lstm = plt.figure(figsize=(12, 5))
    plt.plot(y_test_inv, label='Actual Sales')
    plt.plot(y_pred, label='Predicted Sales')
    plt.title("LSTM Forecast vs Actual Sales")
    plt.legend()
    st.pyplot(fig_lstm)
    st.write("---")

# --- LightGBM Model ---
def run_lightgbm_model(df_final, st):
    st.subheader("Mô hình Dự báo: LightGBM")
    st.write("---")

    df = df_final.copy()
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.sort_values('Date').set_index('Date')

    # Resample and aggregate
    daily = pd.DataFrame(index=pd.date_range(df.index.min(), df.index.max(), freq='D'))
    daily['Quantity_Sold'] = df['Quantity_Sold'].resample('D').sum()
    daily['Avg_Price'] = df['Price'].resample('D').mean()
    daily['Total_Stock'] = df['Stock_Level'].resample('D').sum()
    daily['Avg_Reorder_Threshold'] = df['Reorder_Threshold'].resample('D').mean()
    daily['Total_Budget'] = df['Promo_Budget'].resample('D').sum() # Use Promo_Budget
    daily['Avg_Store_Size'] = df['Store_Size'].resample('D').mean()
    daily['Avg_Promo_Code'] = df['Promo_Type_Code'].resample('D').mean()

    # Fill missing values
    daily[['Quantity_Sold','Total_Stock','Total_Budget']].fillna(0, inplace=True)
    for col in ['Avg_Price','Avg_Reorder_Threshold','Avg_Store_Size','Avg_Promo_Code']:
        daily[col].fillna(method='ffill', inplace=True)
        daily[col].fillna(0, inplace=True)

    # Time index and cyclical features
    daily['t'] = np.arange(len(daily))
    daily['sin7'] = np.sin(2 * np.pi * daily['t'] / 7)
    daily['cos7'] = np.cos(2 * np.pi * daily['t'] / 7)
    daily['sin30'] = np.sin(2 * np.pi * daily['t'] / 30)
    daily['cos30'] = np.cos(2 * np.pi * daily['t'] / 30)

    # Lag features
    for lag in [1,7,14,30]:
        daily[f'lag_{lag}'] = daily['Quantity_Sold'].shift(lag).fillna(0)

    # Rolling mean features
    for win in [7,14,30]:
        daily[f'roll_{win}'] = daily['Quantity_Sold'].shift(1).rolling(win).mean().fillna(0)

    # Categorical temporal features
    daily['dow'] = daily.index.dayofweek
    daily['month'] = daily.index.month
    dow_d = pd.get_dummies(daily['dow'], prefix='dow')
    mon_d = pd.get_dummies(daily['month'], prefix='mon')
    daily = daily.join(dow_d).join(mon_d)

    features = [
        't','sin7','cos7','sin30','cos30',
        'Avg_Price','Total_Stock','Avg_Reorder_Threshold',
        'Total_Budget','Avg_Store_Size','Avg_Promo_Code'
    ] + [f'lag_{lag}' for lag in [1,7,14,30]] + [f'roll_{win}' for win in [7,14,30]] + \
     list(dow_d.columns) + list(mon_d.columns)

    # Filter features to only include those present in daily.columns
    features = [f for f in features if f in daily.columns]

    daily.dropna(subset=features+['Quantity_Sold'], inplace=True)

    X = daily[features]
    y = daily['Quantity_Sold']
    split = int(len(daily)*0.8)

    # Ensure split point is valid
    if split == 0 or split >= len(daily):
        st.warning("Không đủ dữ liệu cho việc chia tập train/test trong LightGBM.")
        return

    X_train, X_test = X.iloc[:split], X.iloc[split:]
    y_train, y_test = y.iloc[:split], y.iloc[split:]

    tscv = TimeSeriesSplit(n_splits=3) # Reduced n_splits for faster execution in Streamlit demo
    pipeline = Pipeline([
        ('scale', StandardScaler()),
        ('lgbm', LGBMRegressor(random_state=42))
    ])
    param_grid = {
        'lgbm__n_estimators': [100], # Reduced estimators
        'lgbm__max_depth': [5], # Reduced max_depth
        'lgbm__learning_rate': [0.1] # Single learning rate
    }

    with st.spinner('Đang chạy GridSearchCV cho LightGBM...'):
        search = GridSearchCV(pipeline, param_grid,
                              cv=tscv,
                              scoring='neg_mean_absolute_percentage_error',
                              n_jobs=-1)
        search.fit(X_train, y_train)
    best = search.best_estimator_
    st.success("LightGBM GridSearchCV hoàn tất.")

    y_pred = best.predict(X_test)

    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mape = mean_absolute_percentage_error(y_test, y_pred) * 100
    r2 = r2_score(y_test, y_pred)

    st.write("#### Kết quả đánh giá mô hình:")
    st.write(f"**MAE:** {mae:.2f}")
    st.write(f"**RMSE:** {rmse:.2f}")
    st.write(f"**MAPE:** {mape:.2f}%")
    st.write(f"**R²:** {r2:.3f}")

    df_test = daily.iloc[split:].copy()
    df_test['Forecast'] = y_pred
    df_test['month'] = pd.DatetimeIndex(df_test.index).month

    # Check if df_test is empty before grouping
    if not df_test.empty:
        seasonal = df_test.groupby('month').apply(lambda x: pd.Series({
            'MAE': mean_absolute_error(x['Quantity_Sold'], x['Forecast']),
            'RMSE': np.sqrt(mean_squared_error(x['Quantity_Sold'], x['Forecast'])),
            'MAPE': mean_absolute_percentage_error(x['Quantity_Sold'], x['Forecast'])*100
        })).reset_index()
        st.write("#### Đánh giá theo mùa (Monthly Seasonal Metrics):")
        st.dataframe(seasonal)
    else:
        st.write("Không đủ dữ liệu thử nghiệm để tính toán các chỉ số theo mùa.")

    fig_lgbm = plt.figure(figsize=(12,5))
    plt.plot(daily.index, daily['Quantity_Sold'], label='Actual')
    plt.plot(daily.index[split:], y_pred, '--', label='LightGBM Forecast')
    plt.title('Actual vs Forecast (LightGBM)')
    plt.xlabel('Date')
    plt.ylabel('Quantity Sold')
    plt.legend()
    plt.tight_layout()
    st.pyplot(fig_lgbm)
    st.write("---")
